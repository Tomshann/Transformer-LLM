# Transformer-LLM
My first context based chatbot using the Transformer architecture

This model was trained using the ambigQA dataset: https://huggingface.co/datasets/sewon/ambig_qa

Due to the training dataset being very small the model is very limited in the quality of output produced based on context however it recognises tokens well and produces legible words although the full response may not make full gramatical sense. This model could be trained on a much larger datasets to see noticeable improvements to the quality of responses.
